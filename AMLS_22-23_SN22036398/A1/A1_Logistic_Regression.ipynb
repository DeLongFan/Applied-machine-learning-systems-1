{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf48977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import skimage.color as color\n",
    "import time\n",
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9372772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelprocessing(label_trainpath,label_testpath):\n",
    "    #Valid data split for read-in training csv, rename table headers, replace all -1's with 0's in order to cater for the 0-1 classification of the formula\n",
    "    raw_data_train=pd.read_csv(label_trainpath,names=[\"mixed_information_train\"])\n",
    "    data_unmixed_train = raw_data_train[\"mixed_information_train\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_train.columns=['index','img_name','gender','smiling']\n",
    "    data_unmixed_train.drop(columns=['index','img_name','smiling'],inplace=True)\n",
    "    data_unmixed_train.drop(index=0,inplace=True)\n",
    "    data_unmixed_train[data_unmixed_train<\"1\"]=0\n",
    "    \n",
    "    #Perform the same processing on the read-in test set results\n",
    "    raw_data_test=pd.read_csv(label_testpath,names=[\"mixed_information_test\"])\n",
    "    data_unmixed_test = raw_data_test[\"mixed_information_test\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_test.columns=['index','img_name','gender','smiling']\n",
    "    data_unmixed_test.drop(columns=['index','img_name','smiling'],inplace=True)\n",
    "    data_unmixed_test.drop(index=0,inplace=True)\n",
    "    data_unmixed_test[data_unmixed_test<\"1\"]=0\n",
    "    \n",
    "    #Converting label information into a form that is actually used \n",
    "    YTrain=data_unmixed_train\n",
    "    YTest=data_unmixed_test\n",
    "    YTrain=YTrain.values\n",
    "    YTest=YTest.values\n",
    "    YTrain=np.array([int(y) for y in YTrain])\n",
    "    YTest=np.array([int(y) for y in YTest])\n",
    "    YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    YTest=YTest.reshape(len(YTest),1)\n",
    "    \n",
    "    return(YTrain,YTest)\n",
    "\n",
    "def data_preprocessing(data_trainpath,data_testpath):\n",
    "    XTrain=[]\n",
    "    XTest=[]\n",
    "    n_components=300\n",
    "    coll_train = io.ImageCollection(data_trainpath)\n",
    "    coll_test = io.ImageCollection(data_testpath)\n",
    "\n",
    "    for img in coll_train:\n",
    "        intern_train=change_shape(color.rgb2gray(img))\n",
    "        XTrain.append(intern_train)\n",
    "    XTrain=np.array(XTrain)/255.\n",
    "    pca=PCA(n_components=n_components,svd_solver='randomized',whiten=True).fit(XTrain)\n",
    "    XTrain = pca.transform(XTrain)\n",
    "    for img in coll_test:\n",
    "        intern_test=change_shape(color.rgb2gray(img))\n",
    "        XTest.append(intern_test)\n",
    "    XTest=np.array(XTest)/255.\n",
    "    XTest = pca.transform(XTest)\n",
    "    XTrain=np.insert(XTrain,0,values=1,axis=1)\n",
    "    XTest=np.insert(XTest,0,values=1,axis=1)\n",
    "    return(XTrain,XTest)\n",
    "\n",
    "def change_shape(img):\n",
    "    [row,col]=img.shape\n",
    "    img=img.reshape(row*col,)\n",
    "    return img\n",
    "\n",
    "def costfunction(X,Y,theta,lamda):\n",
    "    h_theta=sigmoid(X@theta)\n",
    "    firstpart=Y*np.log(h_theta + 1e-6)\n",
    "    secondpart=(1-Y)*np.log(1-h_theta + 1e-6)\n",
    "    thirdpart=(lamda/(2*len(X)))*np.sum(np.power(theta[1:],2))\n",
    "    return (-np.sum(firstpart+secondpart)/len(X))+thirdpart\n",
    "\n",
    "def gradient_descent(X,Y,theta,rounds,alpha,lamda):\n",
    "    costs=[]\n",
    "    for i in range(rounds):\n",
    "        thirdpart_derivative=theta[1:]*(lamda/len(X))\n",
    "        thirdpart_derivative=np.insert(thirdpart_derivative,0,values=0,axis=0)\n",
    "        h_theta=sigmoid(X@theta)\n",
    "        theta=theta-(alpha/len(X))*X.T@(h_theta-Y)-thirdpart_derivative\n",
    "        cost=costfunction(X,Y,theta,lamda)\n",
    "        costs.append(cost)\n",
    "    return costs,theta\n",
    "\n",
    "def average_num(array):\n",
    "    sum=0\n",
    "    for i in range (len(array)):\n",
    "        sum=sum+array[i]\n",
    "    return sum/len(array)\n",
    "\n",
    "def find_best_lamda(theta_inital,rounds,alpha,lamda,Trainingset):\n",
    "    costs_all=[]\n",
    "    theta_all=[]\n",
    "    accurancy_all=[]\n",
    "    for train, test in KF.split(Trainingset):\n",
    "        XTrain=Trainingset[train][:,:-1]\n",
    "        YTrain=Trainingset[train][:,-1]\n",
    "        XTest_crossvalidation=Trainingset[test][:,:-1]\n",
    "        YTest_crossvalidatio=Trainingset[test][:,-1]\n",
    "    \n",
    "        YTest_crossvalidatio=YTest_crossvalidatio.reshape(len(YTest_crossvalidatio),1)\n",
    "        YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    \n",
    "        costs,theta=gradient_descent(XTrain,YTrain,theta_inital,rounds,alpha,lamda)\n",
    "        accurancy=Judge(XTest_crossvalidation,theta,YTest_crossvalidatio)\n",
    "        costs_all.append(costs)\n",
    "        theta_all.append(theta)\n",
    "        accurancy_all.append(accurancy)\n",
    "    return lamda,average_num(accurancy_all),accurancy_all\n",
    "\n",
    "def Judge(X,theta,Label):\n",
    "    h=sigmoid(X@theta)\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    for i in range(len(h)):\n",
    "        if h[i]>0.5:\n",
    "            h[i]=1\n",
    "        else:\n",
    "            h[i]=0\n",
    "    for i in range(len(Label)):\n",
    "        if h[i]==1 and Label[i]==1:\n",
    "            TP=TP+1\n",
    "        elif h[i]==0 and Label[i]==0:\n",
    "            TN=TN+1\n",
    "        elif h[i]==1 and Label[i]==0:\n",
    "            FN=FN+1\n",
    "        elif h[i]==0 and Label[i]==1:\n",
    "            FP=FP+1\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    accurancy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    F1_score=(2*precision*recall)/(precision+recall)\n",
    "    #return precision,recall,accurancy,F1_score\n",
    "    return accurancy\n",
    "\n",
    "def crossvalidation(data_trainpath,data_testpath,label_trainpath,label_testpath):\n",
    "    import time\n",
    "    start=time.perf_counter()\n",
    "    alpha=2\n",
    "    rounds=150\n",
    "    lamda=1\n",
    "    costs_all=[]\n",
    "    accurancy_all=[]\n",
    "    theta_all=[]\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=data_preprocessing(data_trainpath,data_testpath)\n",
    "    #After the hstack, the last column of the Trainingset is the YTrain, which can then be scaled for splitting.\n",
    "    Trainingset=np.hstack((XTrain,YTrain))\n",
    "    Trainingset=np.array(Trainingset)\n",
    "    KF=KFold(n_splits=10)\n",
    "    theta_inital=np.zeros((len(XTrain.T),1))\n",
    "    for train, test in KF.split(Trainingset):\n",
    "        XTrain=Trainingset[train][:,:-1]\n",
    "        YTrain=Trainingset[train][:,-1]\n",
    "        XTest_crossvalidation=Trainingset[test][:,:-1]\n",
    "        YTest_crossvalidatio=Trainingset[test][:,-1]\n",
    "\n",
    "        YTest_crossvalidatio=YTest_crossvalidatio.reshape(len(YTest_crossvalidatio),1)\n",
    "        YTrain=YTrain.reshape(len(YTrain),1)\n",
    "\n",
    "        costs,theta=gradient_descent(XTrain,YTrain,theta_inital,rounds,alpha,lamda)\n",
    "        accurancy=Judge(XTest_crossvalidation,theta,YTest_crossvalidatio)\n",
    "        costs_all.append(costs)\n",
    "        theta_all.append(theta)\n",
    "        accurancy_all.append(accurancy)\n",
    "    end=time.perf_counter()\n",
    "    time=end-start\n",
    "    accurancy_all_average=np.sum(accurancy_all)/len(accurancy_all)\n",
    "    return accurancy_all_average,theta_all,costs_all,time\n",
    "\n",
    "def main(data_trainpath,data_testpath,label_trainpath,label_testpath):\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=data_preprocessing(data_trainpath,data_testpath)\n",
    "    theta=theta_all[0]\n",
    "    accurancy=Judge(XTest,theta,YTest)\n",
    "    return accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9525190",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trainpath= r\".\\Datasets\\celeba\\img\\*.jpg\"\n",
    "data_testpath= r\".\\Datasets\\celeba_test\\img\\*.jpg\"\n",
    "label_trainpath=r\".\\Datasets\\celeba\\labels.csv\"\n",
    "label_testpath=r\".\\Datasets\\celeba_test\\labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfbccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877\n"
     ]
    }
   ],
   "source": [
    "accurancy_all,theta_all,costs_all,time=crossvalidation(data_trainpath,data_testpath,label_trainpath,label_testpath)\n",
    "accurancy=main(data_trainpath,data_testpath,label_trainpath,label_testpath)\n",
    "print(\"TaskA1: Accuracy of Logistic Regression is {}\".format(accurancy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8525a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import skimage.color as color\n",
    "import scipy.special\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eafeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelprocessing(label_trainpath,label_testpath):\n",
    "    #Valid data split for read-in training csv, rename table headers, replace all -1's with 0's in order to cater for the 0-1 classification of the formula\n",
    "    raw_data_train=pd.read_csv(label_trainpath,names=[\"mixed_information_train\"])\n",
    "    data_unmixed_train = raw_data_train[\"mixed_information_train\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_train.columns=['index','img_name','gender','smiling']\n",
    "    data_unmixed_train.drop(columns=['index','img_name','smiling'],inplace=True)\n",
    "    data_unmixed_train.drop(index=0,inplace=True)\n",
    "    data_unmixed_train[data_unmixed_train<\"1\"]=0\n",
    "    \n",
    "    #Perform the same processing on the read-in test set results\n",
    "    raw_data_test=pd.read_csv(label_testpath,names=[\"mixed_information_test\"])\n",
    "    data_unmixed_test = raw_data_test[\"mixed_information_test\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_test.columns=['index','img_name','gender','smiling']\n",
    "    data_unmixed_test.drop(columns=['index','img_name','smiling'],inplace=True)\n",
    "    data_unmixed_test.drop(index=0,inplace=True)\n",
    "    data_unmixed_test[data_unmixed_test<\"1\"]=0\n",
    "    \n",
    "    #Converting label information into a form that is actually used \n",
    "    YTrain=data_unmixed_train\n",
    "    YTest=data_unmixed_test\n",
    "    YTrain=YTrain.values\n",
    "    YTest=YTest.values\n",
    "    YTrain=np.array([int(y) for y in YTrain])\n",
    "    YTest=np.array([int(y) for y in YTest])\n",
    "    YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    YTest=YTest.reshape(len(YTest),1)\n",
    "    \n",
    "    return(YTrain,YTest)\n",
    "\n",
    "def data_preprocessing(data_trainpath,data_testpath):\n",
    "    XTrain=[]\n",
    "    XTest=[]\n",
    "    n_components=300\n",
    "    coll_train = io.ImageCollection(data_trainpath)\n",
    "    coll_test = io.ImageCollection(data_testpath)\n",
    "\n",
    "    for img in coll_train:\n",
    "        intern_train=change_shape(color.rgb2gray(img))\n",
    "        XTrain.append(intern_train)\n",
    "    XTrain=np.array(XTrain)/255.\n",
    "    pca=PCA(n_components=n_components,svd_solver='randomized',whiten=True).fit(XTrain)\n",
    "    XTrain = pca.transform(XTrain)\n",
    "    for img in coll_test:\n",
    "        intern_test=change_shape(color.rgb2gray(img))\n",
    "        XTest.append(intern_test)\n",
    "    XTest=np.array(XTest)/255.\n",
    "    XTest = pca.transform(XTest)\n",
    "    XTrain=np.insert(XTrain,0,values=1,axis=1)\n",
    "    XTest=np.insert(XTest,0,values=1,axis=1)\n",
    "    return(XTrain,XTest)\n",
    "\n",
    "def change_shape(img):\n",
    "    [row,col]=img.shape\n",
    "    img=img.reshape(row*col,)\n",
    "    return img\n",
    "\n",
    "def Judge(X,theta,Label):\n",
    "    h=sigmoid(X@theta)\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    for i in range(len(h)):\n",
    "        if h[i]>0.5:\n",
    "            h[i]=1\n",
    "        else:\n",
    "            h[i]=0\n",
    "    for i in range(len(Label)):\n",
    "        if h[i]==1 and Label[i]==1:\n",
    "            TP=TP+1\n",
    "        elif h[i]==0 and Label[i]==0:\n",
    "            TN=TN+1\n",
    "        elif h[i]==1 and Label[i]==0:\n",
    "            FN=FN+1\n",
    "        elif h[i]==0 and Label[i]==1:\n",
    "            FP=FP+1\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    accurancy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    F1_score=(2*precision*recall)/(precision+recall)\n",
    "    #return precision,recall,accurancy,F1_score\n",
    "    return accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d01c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_kernel(data_trainpath,data_testpath,label_trainpath,label_testpath):\n",
    "    import time\n",
    "    Kernel=['linear','rbf','sigmoid','']\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=data_preprocessing(data_trainpath,data_testpath)\n",
    "    YTrain=YTrain.reshape(len(YTrain),)\n",
    "    start=time.perf_counter()\n",
    "    for kernel in Kernel:\n",
    "        svc=SVC(kernel=kernel,gamma='auto',cache_size=10000)\n",
    "        svc.fit(XTrain,YTrain)\n",
    "        end=time.perf_counter()\n",
    "        time=end-start\n",
    "        acc=svc.score(XTest,YTest.flatten())\n",
    "        print(time,acc)\n",
    "    return time,acc\n",
    "def crossvalidation(data_trainpath,data_testpath,label_trainpath,label_testpath):\n",
    "    import time\n",
    "    gamma=[]\n",
    "    C=[]\n",
    "    c=0.1\n",
    "    g=1/100000\n",
    "    for i in range(10):\n",
    "        gamma.append(g)\n",
    "        C.append(c)\n",
    "        g=2*g\n",
    "        c=c*1.5\n",
    "    accurancy_all=[]\n",
    "    search=[]\n",
    "    start=time.perf_counter()\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=data_preprocessing(data_trainpath,data_testpath)\n",
    "    #After the hstack, the last column of the Trainingset is the YTrain, which can then be scaled for splitting.\n",
    "    Trainingset=np.hstack((XTrain,YTrain))\n",
    "    Trainingset=np.array(Trainingset)\n",
    "    KF=KFold(n_splits=10)\n",
    "    for train, test in KF.split(Trainingset): \n",
    "        XTrain=Trainingset[train][:,:-1]\n",
    "        YTrain=Trainingset[train][:,-1]\n",
    "        XTest_crossvalidation=Trainingset[test][:,:-1]\n",
    "        YTest_crossvalidatio=Trainingset[test][:,-1]\n",
    "        YTest_crossvalidatio=YTest_crossvalidatio.reshape(len(YTest_crossvalidatio),1)\n",
    "        YTrain=YTrain.reshape(len(YTrain),1)\n",
    "        for i in C:\n",
    "            for j in gamma:\n",
    "                svc = SVC(C=i, gamma=j,kernel=\"rbf\")\n",
    "                svc.fit(XTrain,YTrain)\n",
    "                search.append(svc.score(XTest_crossvalidation,YTest_crossvalidatio.flatten()))\n",
    "                best_score = search[np.argmax(search)]   \n",
    "                best_param = [np.argmax(search)] \n",
    "                #print(metrics.classification_report(YTest_crossvalidatio, svc.predict(XTest_crossvalidation)))\n",
    "    end=time.perf_counter()\n",
    "    time=end-start\n",
    "    accurancy_all_average=np.sum(accurancy_all)/len(accurancy_all)\n",
    "    return best_param,best_score,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc385e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_trainpath,data_testpath,label_trainpath,label_testpath):\n",
    "    import time\n",
    "    from sklearn.metrics import plot_roc_curve,roc_curve,auc,roc_auc_score\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=data_preprocessing(data_trainpath,data_testpath)\n",
    "    YTrain=YTrain.reshape(len(YTrain),)\n",
    "    start=time.perf_counter()\n",
    "    svc=SVC(C=3.32,kernel='rbf',gamma=0.000202)\n",
    "    svc.fit(XTrain,YTrain)\n",
    "    end=time.perf_counter()\n",
    "    time=end-start\n",
    "    acc=svc.score(XTest,YTest.flatten())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39c0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trainpath= r\".\\Datasets\\celeba\\img\\*.jpg\"\n",
    "data_testpath= r\".\\Datasets\\celeba_test\\img\\*.jpg\"\n",
    "label_trainpath=r\".\\Datasets\\celeba\\labels.csv\"\n",
    "label_testpath=r\".\\Datasets\\celeba_test\\labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c35031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crossvalidation(data_trainpath,data_testpath,label_trainpath,label_testpath)\n",
    "#score,C,gamma=maina(data_trainpath,data_testpath,label_trainpath,label_testpath)\n",
    "acc=main(data_trainpath,data_testpath,label_trainpath,label_testpath)\n",
    "print(\"TaskA1: Accuracy of Support Vector Machine is {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f550bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf72c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelprocessing(label_trainpath,label_testpath):\n",
    "    #Valid data splitting of read-in training csv, table header renaming\n",
    "    raw_data_train=pd.read_csv(label_trainpath,names=[\"mixed_information_train\"])\n",
    "    data_unmixed_train = raw_data_train[\"mixed_information_train\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_train.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_train.drop(columns=['index','eye_color','file_name'],inplace=True)\n",
    "    data_unmixed_train.drop(index=0,inplace=True)\n",
    "    #Perform the same processing on the read-in test set results\n",
    "    raw_data_test=pd.read_csv(label_testpath,names=[\"mixed_information_test\"])\n",
    "    data_unmixed_test = raw_data_test[\"mixed_information_test\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_test.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_test.drop(columns=['index','eye_color','file_name'],inplace=True)\n",
    "    data_unmixed_test.drop(index=0,inplace=True)\n",
    "    #Store the results of training and testing as arrays\n",
    "    YTrain=data_unmixed_train\n",
    "    YTest=data_unmixed_test\n",
    "    YTrain=YTrain.values\n",
    "    YTest=YTest.values\n",
    "    YTrain=np.array([int(y) for y in YTrain])\n",
    "    YTest=np.array([int(y) for y in YTest])\n",
    "    YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    YTest=YTest.reshape(len(YTest),1)\n",
    "    \n",
    "    return YTrain,YTest\n",
    "\n",
    "def datapreprocessing(data_train_path,data_test_path):\n",
    "    XTrain_tmp=[]\n",
    "    XTest_tmp=[]\n",
    "    XTrain=[]\n",
    "    XTest=[]\n",
    "    coll_train = io.ImageCollection(data_train_path)\n",
    "    coll_test = io.ImageCollection(data_test_path)\n",
    "    for img in coll_train:\n",
    "        intern_train=cv2.resize(img, (120,120))\n",
    "        XTrain_tmp.append(intern_train)\n",
    "    XTrain_tmp=np.array(XTrain_tmp)/255\n",
    "    for img in coll_test:\n",
    "        intern_test=cv2.resize(img, (120,120))\n",
    "        XTest_tmp.append(intern_test)\n",
    "    XTest_tmp=np.array(XTest_tmp)/255\n",
    "    for (i,value) in enumerate(XTest_tmp):\n",
    "        XTest.append(value.flatten())\n",
    "    for (i,value) in enumerate(XTrain_tmp):\n",
    "        XTrain.append(value.flatten())\n",
    "    XTrain=np.array(XTrain)\n",
    "    XTest=np.array(XTest)\n",
    "    XTrain=XTrain.reshape(len(XTrain),120,120,4)\n",
    "    XTest=XTest.reshape(len(XTest),120,120,4)\n",
    "    return XTrain,XTest\n",
    "\n",
    "def predict(XTrain,YTrain):\n",
    "    conv_num=[3]\n",
    "    fully_connected_layer_num=[4]\n",
    "    unit_count=[100]\n",
    "    for conv in conv_num:\n",
    "        for fully_connected_layer in fully_connected_layer_num:\n",
    "            for unit in unit_count:\n",
    "                logs_file=f'logs/log_{conv}_fully_{fully_connected_layer}_unit_{unit}_conv_{int(time.time())}'\n",
    "                tensorboard=TensorBoard(log_dir=logs_file)\n",
    "                #checkpoint\n",
    "                checkpoint_filepath=f'models/model_{conv}_fully_{fully_connected_layer}_unit_{unit}_'+'{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "                print(logs_file)\n",
    "                print(checkpoint_filepath)\n",
    "                checkpoint=ModelCheckpoint(filepath=checkpoint_filepath,monitor='val_accuracy',model='max',save_best_only=True,verbose=1)\n",
    "                model=Sequential()\n",
    "                #convention and maxpooling \n",
    "                for i in range(conv):\n",
    "                    #convloution layer\n",
    "                    model.add(Conv2D(unit,(2,2),activation='relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "                #Flatten layer\n",
    "                model.add(Flatten())\n",
    "                #fully connected layer\n",
    "                for i in range(fully_connected_layer):\n",
    "                    model.add(Dense(unit,activation='relu'))\n",
    "                #output layer\n",
    "                model.add(Dense(5,activation='softmax'))\n",
    "                #compile\n",
    "                model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "                #fit\n",
    "                model.fit(XTrain,YTrain,batch_size=32,epochs=5,callbacks=[tensorboard])\n",
    "    return model\n",
    "\n",
    "def acc_Test(model,XTest,YTest):\n",
    "    Yres=[]\n",
    "    res=model.predict(XTest)\n",
    "    for i in range(len(res)):\n",
    "        Yres.append(np.argmax(res[i]))\n",
    "    Yres=np.array(Yres)\n",
    "    acc=np.mean(Yres==YTest.flatten())\n",
    "    return acc\n",
    "def main(label_trainpath,label_testpath,data_train_path,data_test_path):\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=datapreprocessing(data_train_path,data_test_path)\n",
    "    model=predict(XTrain,YTrain)\n",
    "    acc=acc_Test(model,XTest,YTest)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16887223",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_trainpath=r\".\\Datasets\\cartoon_set\\labels.csv\"\n",
    "label_testpath=r\".\\Datasets\\cartoon_set_test\\labels.csv\"\n",
    "data_train_path=r\".\\Datasets\\cartoon_set\\img\\*.png\"\n",
    "data_test_path= r\".\\Datasets\\cartoon_set_test\\img\\*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeef3bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/log_2_fully_5_unit_100_conv_1672783287\n",
      "models/model_2_fully_5_unit_100_{epoch:02d}-{val_accuracy:.2f}.hdf5\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 45s 137ms/step - loss: 0.7304 - accuracy: 0.6741\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.0389 - accuracy: 0.9859\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0171 - accuracy: 0.9943\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "79/79 [==============================] - 4s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "acc=main(label_trainpath,label_testpath,data_train_path,data_test_path)\n",
    "print(\"TaskB1: Accuracy of Convolutional Neural Network is {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da256e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing of the label set data into the form used in the model\n",
    "def labelprocessing(label_trainpath,label_testpath):\n",
    "    #Valid data splitting of read-in training csv, table header renaming\n",
    "    raw_data_train=pd.read_csv(label_trainpath,names=[\"mixed_information_train\"])\n",
    "    data_unmixed_train = raw_data_train[\"mixed_information_train\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_train.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_train.drop(columns=['index','eye_color','file_name'],inplace=True)\n",
    "    data_unmixed_train.drop(index=0,inplace=True)\n",
    "    #Perform the same processing on the read-in test set results\n",
    "    raw_data_test=pd.read_csv(label_testpath,names=[\"mixed_information_test\"])\n",
    "    data_unmixed_test = raw_data_test[\"mixed_information_test\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_test.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_test.drop(columns=['index','eye_color','file_name'],inplace=True)\n",
    "    data_unmixed_test.drop(index=0,inplace=True)\n",
    "    #Store the results of training and testing as arrays\n",
    "    YTrain=data_unmixed_train\n",
    "    YTest=data_unmixed_test\n",
    "    YTrain=YTrain.values\n",
    "    YTest=YTest.values\n",
    "    YTrain=np.array([int(y) for y in YTrain])\n",
    "    YTest=np.array([int(y) for y in YTest])\n",
    "    YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    YTest=YTest.reshape(len(YTest),1)\n",
    "    \n",
    "    return YTrain,YTest\n",
    "\n",
    "#Downscaling high-dimensional images\n",
    "def change_shape(img):\n",
    "    [NUM,row,col,dimension]=img.shape\n",
    "    img=img.reshape(NUM,row*col*dimension)\n",
    "    return img\n",
    "\n",
    "#Processing of the data set data into the form used in the model,includes reading, image dimensionality reduction and normalisation, processing of input data\n",
    "def datapreprocessing(data_train_path,data_test_path):\n",
    "    XTrain_tmp=[]\n",
    "    XTest_tmp=[]\n",
    "    XTrain=[]\n",
    "    XTest=[]\n",
    "    coll_train = io.ImageCollection(data_train_path)\n",
    "    coll_test = io.ImageCollection(data_test_path)\n",
    "    for img in coll_train:\n",
    "        intern_train=cv2.resize(img, (120,120))\n",
    "        XTrain_tmp.append(intern_train)\n",
    "    XTrain_tmp=np.array(XTrain_tmp)/255\n",
    "    for img in coll_test:\n",
    "        intern_test=cv2.resize(img, (120,120))\n",
    "        XTest_tmp.append(intern_test)\n",
    "    XTest_tmp=np.array(XTest_tmp)/255\n",
    "    for (i,value) in enumerate(XTest_tmp):\n",
    "        XTest.append(value.flatten())\n",
    "    for (i,value) in enumerate(XTrain_tmp):\n",
    "        XTrain.append(value.flatten())\n",
    "    XTrain=np.array(XTrain)\n",
    "    XTest=np.array(XTest)\n",
    "    XTrain=XTrain.reshape(len(XTrain),120,120,4)\n",
    "    XTest=XTest.reshape(len(XTest),120,120,4)\n",
    "    return XTrain,XTest\n",
    "\n",
    "#Performing PCA on the input data and building neural networks\n",
    "def predict(XTrain,YTrain):\n",
    "    import time\n",
    "    XTrain=change_shape(XTrain)\n",
    "    pca=PCA(n_components=200,svd_solver='randomized',whiten=True).fit(XTrain)\n",
    "    XTrain = pca.transform(XTrain)\n",
    "    start=time.perf_counter()\n",
    "    fully_connected_layer_num=[3]\n",
    "    unit_count=[200]\n",
    "    for fully_connected_layer in fully_connected_layer_num:\n",
    "        for unit in unit_count:\n",
    "            model=Sequential()\n",
    "            for i in range(fully_connected_layer):\n",
    "                model.add(Dense(unit,activation='relu'))\n",
    "            #output layer\n",
    "            model.add(Dense(5,activation='softmax'))\n",
    "            #compile\n",
    "            model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "            #fit\n",
    "            model.fit(XTrain,YTrain,batch_size=64,epochs=5)\n",
    "    end=time.perf_counter()\n",
    "    time=end-start\n",
    "    return model,pca,time\n",
    "\n",
    "#Return Forecast Results\n",
    "def acc_Test(model,XTest,YTest):\n",
    "    Yres=[]\n",
    "    res=model.predict(XTest)\n",
    "    for i in range(len(res)):\n",
    "        Yres.append(np.argmax(res[i]))\n",
    "    Yres=np.array(Yres)\n",
    "    acc=np.mean(Yres==YTest.flatten())\n",
    "    return acc\n",
    "\n",
    "def main(label_trainpath,label_testpath,data_train_path,data_test_path):\n",
    "    YTrain,YTest=labelprocessing(label_trainpath,label_testpath)\n",
    "    XTrain,XTest=datapreprocessing(data_train_path,data_test_path)\n",
    "    model,pca,time=predict(XTrain,YTrain)\n",
    "    XTest=change_shape(XTest)\n",
    "    XTest = pca.transform(XTest)\n",
    "    acc=acc_Test(model,XTest,YTest)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf99fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths\n",
    "label_trainpath=r\".\\Datasets\\cartoon_set\\labels.csv\"\n",
    "label_testpath=r\".\\Datasets\\cartoon_set_test\\labels.csv\"\n",
    "data_train_path=r\".\\Datasets\\cartoon_set\\img\\*.png\"\n",
    "data_test_path= r\".\\Datasets\\cartoon_set_test\\img\\*.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b607c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.3752 - accuracy: 0.8721\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9957\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9988\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9968\n",
      "79/79 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "acc=main(label_trainpath,label_testpath,data_train_path,data_test_path)\n",
    "print(\"TaskB1: Accuracy of Fully Connected Neural Network is {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

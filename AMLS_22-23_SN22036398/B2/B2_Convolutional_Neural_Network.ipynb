{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdea70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1429b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing of the label set data into the form used in the model\n",
    "def labelprocessing(label_trainpath,label_testpath,glass_label_path):\n",
    "    \n",
    "    raw_data_train=pd.read_csv(label_trainpath,names=[\"mixed_information_train\"])\n",
    "    data_unmixed_train = raw_data_train[\"mixed_information_train\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_train.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_train.drop(columns=['index','face_shape','file_name'],inplace=True)\n",
    "    data_unmixed_train.drop(index=0,inplace=True)\n",
    "    \n",
    "    raw_data_test=pd.read_csv(label_testpath,names=[\"mixed_information_test\"])\n",
    "    data_unmixed_test = raw_data_test[\"mixed_information_test\"].str.split(\"\\t\",expand=True)\n",
    "    data_unmixed_test.columns=['index','eye_color','face_shape','file_name']\n",
    "    data_unmixed_test.drop(columns=['index','face_shape','file_name'],inplace=True)\n",
    "    data_unmixed_test.drop(index=0,inplace=True)\n",
    "\n",
    "    raw_data_newlabel=pd.read_csv(glass_label_path,names=[\"sunglass\"])\n",
    "    #raw_data_newlabel.head()\n",
    "    \n",
    "    \n",
    "    YTrain=data_unmixed_train\n",
    "    YTrain_newlabel=raw_data_newlabel\n",
    "    YTest=data_unmixed_test\n",
    "    YTrain=YTrain.values\n",
    "    YTrain_newlabel=YTrain_newlabel.values\n",
    "    YTest=YTest.values\n",
    "    YTrain=np.array([int(y) for y in YTrain])\n",
    "    YTrain_newlabel=np.array([int(y) for y in YTrain_newlabel])\n",
    "    YTest=np.array([int(y) for y in YTest])\n",
    "    YTrain=YTrain.reshape(len(YTrain),1)\n",
    "    YTrain_newlabel=YTrain_newlabel.reshape(len(YTrain_newlabel),1)\n",
    "    YTest=YTest.reshape(len(YTest),1)\n",
    "    \n",
    "    return YTrain,YTest,YTrain_newlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbfe4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing of the input data, splitting the training set into labeled data and data awaiting labeling, in preparation for semi-supervised learning\n",
    "def datapreprocessing(data_train_path,data_test_path):\n",
    "    XTrain=[]\n",
    "    XTrain_newlabel_raw=[]\n",
    "    XTrain_newlabel=[]\n",
    "    XTrain_predict=[]\n",
    "    XTest_temp=[]\n",
    "    XTest=[]\n",
    "    coll_train = io.ImageCollection(data_train_path)\n",
    "    coll_test = io.ImageCollection(data_test_path)\n",
    "    for img in coll_train:\n",
    "        intern_train=cv2.resize(img, (120,120))\n",
    "        XTrain.append(intern_train)\n",
    "    XTrain=np.array(XTrain)/255\n",
    "    for img in coll_test:\n",
    "        intern_test=cv2.resize(img, (120,120))\n",
    "        XTest_temp.append(intern_test)\n",
    "    XTest_temp=np.array(XTest_temp)/255\n",
    "    XTrain_newlabel_raw=XTrain[:500,:,:,:]\n",
    "    #XTrain_newlabel is the first 500 training data containing labels\n",
    "    #XTrain_predict is the data waiting to be given a label\n",
    "    for (i,value) in enumerate(XTrain_newlabel_raw):\n",
    "        XTrain_newlabel.append(value.flatten())\n",
    "    for (i,value) in enumerate(XTrain):\n",
    "        XTrain_predict.append(value.flatten()) \n",
    "    for (i,value) in enumerate(XTest_temp):\n",
    "        XTest.append(value.flatten())\n",
    "    XTrain_newlabel=np.array(XTrain_newlabel)\n",
    "    XTrain_predict=np.array(XTrain_predict)\n",
    "    return XTrain,XTest,XTrain_newlabel,XTrain_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "166ba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting and testing models\n",
    "def crossvalidation_judgeglass(XTrain_newlabel,YTrain_newlabel):\n",
    "    rf=RandomForestClassifier(max_depth=50,n_estimators=100)\n",
    "    rf.fit(XTrain_newlabel,YTrain_newlabel)  \n",
    "    return rf          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67620f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label construction and input data reconstruction\n",
    "def creatlable_judgeglass(XTrain_predict,rf,YTrain):\n",
    "    YTrain_glass=[]\n",
    "    YTrain_noglass=[]\n",
    "    XTrain_glass=[]\n",
    "    XTrain_noglass=[]\n",
    "    creat_label=rf.predict(XTrain_predict)\n",
    "    creat_label=np.array(creat_label)\n",
    "    for i in range (len(creat_label)):\n",
    "        if creat_label[i]==1:\n",
    "            XTrain_glass.append(XTrain_predict[i])\n",
    "            YTrain_glass.append(YTrain[i])\n",
    "        elif creat_label[i]==0:\n",
    "            XTrain_noglass.append(XTrain_predict[i])\n",
    "            YTrain_noglass.append(YTrain[i])\n",
    "    XTrain_glass=np.array(XTrain_glass)\n",
    "    XTrain_glass=XTrain_glass.reshape(len(XTrain_glass),120,120,4)\n",
    "    XTrain_noglass=np.array(XTrain_noglass)\n",
    "    XTrain_noglass=XTrain_noglass.reshape(len(XTrain_noglass),120,120,4)\n",
    "    YTrain_glass=np.array(YTrain_glass)\n",
    "    YTrain_noglass=np.array(YTrain_noglass)\n",
    "    return XTrain_noglass,XTrain_glass,YTrain_noglass,YTrain_glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc60b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Convolutional Neural Networks\n",
    "def predict_withnoglass(XTrain_noglass,YTrain_noglass):\n",
    "    conv_num=[3]\n",
    "    fully_connected_layer_num=[4]\n",
    "    unit_count=[100]\n",
    "    for conv in conv_num:\n",
    "        for fully_connected_layer in fully_connected_layer_num:\n",
    "            for unit in unit_count:\n",
    "                logs_file=f'logs/log_{conv}_fully_{fully_connected_layer}_unit_{unit}_conv_{int(time.time())}'\n",
    "                tensorboard=TensorBoard(log_dir=logs_file)\n",
    "                #checkpoint\n",
    "                checkpoint_filepath=f'models/model_{conv}_fully_{fully_connected_layer}_unit_{unit}_'+'{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "                print(logs_file)\n",
    "                print(checkpoint_filepath)\n",
    "                checkpoint=ModelCheckpoint(filepath=checkpoint_filepath,monitor='val_accuracy',model='max',save_best_only=True,verbose=1)\n",
    "                model=Sequential()\n",
    "                #convention and maxpooling \n",
    "                for i in range(conv):\n",
    "                    #convloution layer\n",
    "                    model.add(Conv2D(8,(2,2),activation='relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                #Flatten layer\n",
    "                model.add(Flatten())\n",
    "                #fully connected layer\n",
    "                for i in range(fully_connected_layer):\n",
    "                    model.add(Dense(unit,activation='relu'))\n",
    "                #output layer\n",
    "                model.add(Dense(5,activation='softmax'))\n",
    "                #compile\n",
    "                model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "                #fit\n",
    "                model.fit(XTrain_noglass,YTrain_noglass,batch_size=32,epochs=5,callbacks=[tensorboard])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e54701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return Forecast Results\n",
    "def acc_Test(model,XTest_noglass,YTest_noglass):\n",
    "    Yres=[]\n",
    "    res=model.predict(XTest_noglass)\n",
    "    for i in range(len(res)):\n",
    "        Yres.append(np.argmax(res[i]))\n",
    "    Yres=np.array(Yres)\n",
    "    acc=np.mean(Yres==YTest_noglass.flatten())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03bef801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths,where the \"glass_label_path\" file is the label file for the purpose of semi-supervised learning\n",
    "label_trainpath=r\".\\Datasets\\cartoon_set\\labels.csv\"\n",
    "label_testpath=r\".\\Datasets\\cartoon_set_test\\labels.csv\"\n",
    "data_train_path=r\".\\Datasets\\cartoon_set\\img\\*.png\"\n",
    "data_test_path= r\".\\Datasets\\cartoon_set_test\\img\\*.png\"\n",
    "glass_label_path=r\".\\B2\\Semi_supervised_learning_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d2bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(label_trainpath,label_testpath,glass_label_path,data_train_path,data_test_path):\n",
    "    YTrain,YTest,YTrain_newlabel=labelprocessing(label_trainpath,label_testpath,glass_label_path)\n",
    "    XTrain,XTest,XTrain_newlabel,XTrain_predict=datapreprocessing(data_train_path,data_test_path)\n",
    "    rf=crossvalidation_judgeglass(XTrain_newlabel,YTrain_newlabel)\n",
    "    XTrain_noglass,XTrain_glass,YTrain_noglass,YTrain_glass=creatlable_judgeglass(XTrain_predict,rf,YTrain)\n",
    "    XTest_noglass,XTest_glass,YTest_noglass,YTest_glass=creatlable_judgeglass(XTest,rf,YTest)\n",
    "    model=predict_withnoglass(XTrain_noglass,YTrain_noglass)\n",
    "    acc=acc_Test(model,XTest_noglass,YTest_noglass)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2488e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdl\\AppData\\Local\\Temp\\ipykernel_27788\\513237490.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(XTrain_newlabel,YTrain_newlabel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/log_3_fully_4_unit_100_conv_1673522923\n",
      "models/model_3_fully_4_unit_100_{epoch:02d}-{val_accuracy:.2f}.hdf5\n",
      "Epoch 1/5\n",
      "255/255 [==============================] - 11s 36ms/step - loss: 1.2634 - accuracy: 0.4283\n",
      "Epoch 2/5\n",
      "255/255 [==============================] - 9s 35ms/step - loss: 0.4308 - accuracy: 0.8952\n",
      "Epoch 3/5\n",
      "255/255 [==============================] - 9s 36ms/step - loss: 0.2123 - accuracy: 0.9532\n",
      "Epoch 4/5\n",
      "255/255 [==============================] - 9s 36ms/step - loss: 0.1641 - accuracy: 0.9618\n",
      "Epoch 5/5\n",
      "255/255 [==============================] - 9s 34ms/step - loss: 0.1338 - accuracy: 0.9652\n",
      "64/64 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "acc=main(label_trainpath,label_testpath,glass_label_path,data_train_path,data_test_path)\n",
    "print(\"TaskB2: Accuracy of Convolutional Neural Network is {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
